We create four instances of a Knapsack with 5 items. For each instance, we create a QAOA and optimize it
with different values over the following parameters:

	1. p value
	2. param_type
	3. init_type
	4. mixer_hams
	5. optimizers.

For each combination of parameters, we output an image for the cost history and a json file with the QAOAResult
instance. You can see the code notebook,imgs results, jsons results and experiment conditions for each problem inside
their respective folders (i.e. for problem 1, look in folder "problem1").

After this, we create some excel tables with some comparisons over the results obtained in each of the 4 experiments.
The description for the excel table is:

	1. name: shows the parameters for that QAOA optimization.

	2. lowest cost: aprox. lowest cost seen in the cost history image.

	3. number of iterations: aprox. number of iterations seen in the cost history image.
	
	4. lowest cost is last cost?: a Y/N answer that says if the last cost of the cost history image is
	the lowest cost. This is useful because, if the lowest cost is good but is not the last one of the cost
	history, it could be convenient to iterate over the 'intermediate_cost' list to find that lowest cost.

	5. agree on local min?: a Y/N answer that says if the cost history tends to agree in a local min, instead of
	doing random jumps over different costs. This answer is really subjective and you should consider it as a fact.
	Anyways, is good point of view to take in consideration. 
